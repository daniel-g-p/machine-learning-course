{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import joblib\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_test_split(X, y):\n",
    "    length_X, length_y = len(X), len(y)\n",
    "    n = length_X if length_X == length_y else 0\n",
    "\n",
    "    threshold_1 = round(0.7 * n)\n",
    "    threshold_2 = round(0.85 * n)\n",
    "\n",
    "    X_train, y_train = X[:threshold_1], y[:threshold_1]\n",
    "    X_valid, y_valid = X[threshold_1:threshold_2], y[threshold_1:threshold_2]\n",
    "    X_test, y_test = X[threshold_2:], y[threshold_2:]\n",
    "\n",
    "    return (X_train, y_train, X_valid, y_valid, X_test, y_test)\n",
    "\n",
    "\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"precision\": precision_score(y_true, y_pred, average=\"weighted\"),\n",
    "        \"recall\": recall_score(y_true, y_pred, average=\"weighted\"),\n",
    "        \"f1\": f1_score(y_true, y_pred, average=\"weighted\"),\n",
    "    }\n",
    "\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.2%}\")\n",
    "    print(f\"Precision: {metrics['precision']:.2%}\")\n",
    "    print(f\"Recall: {metrics['recall']:.2%}\")\n",
    "    print(f\"F1 Score: {metrics['f1']:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_wine()\n",
    "\n",
    "df = pd.DataFrame(data[\"data\"], columns=data[\"feature_names\"])\n",
    "df[\"target\"] = data[\"target\"]\n",
    "\n",
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"target\", axis=1)\n",
    "y = df[\"target\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Manual Use of Validation Sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = train_valid_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = RandomForestClassifier(n_estimators=5)\n",
    "model_1.fit(X_train, y_train)\n",
    "evaluate_model(y_test, model_1.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = RandomForestClassifier(n_estimators=10)\n",
    "model_2.fit(X_train, y_train)\n",
    "evaluate_model(y_test, model_2.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = RandomForestClassifier(n_estimators=20)\n",
    "model_3.fit(X_train, y_train)\n",
    "evaluate_model(y_test, model_3.predict(X_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = RandomForestClassifier()\n",
    "\n",
    "param_distributions = {\n",
    "    \"n_estimators\": [5, 25, 100],\n",
    "    \"max_depth\": [None, 10, 50],\n",
    "    \"max_features\": [None, \"sqrt\", \"log2\"],\n",
    "    \"min_samples_split\": [2, 4],\n",
    "    \"min_samples_leaf\": [1, 2],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv_model = GridSearchCV(estimator, param_distributions, cv=5)\n",
    "\n",
    "rscv_model.fit(X_train, y_train)\n",
    "\n",
    "rscv_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(y_test, rscv_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(rscv_model, \"./models/wine-classifier.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
