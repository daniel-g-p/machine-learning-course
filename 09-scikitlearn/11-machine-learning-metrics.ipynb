{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Model Metrics\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Models\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accuracy (Acc): Percentage of predictions that are correct\n",
    "- Precision (Pre) : Percentage of predicted positives that actually are positives\n",
    "- Recall (Rec): Percentage of actual positives that were identified as such\n",
    "- F1 Score (F1): Combined metric of P and R\n",
    "- Confusion Matrix (CM): Color-coded matrix that maps predictions to actual values\n",
    "- Receiver Operating Characteristic (ROC): Curve that maps resulting true positive rate (TPR) to allowed false positive rate (FPR)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Models\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- R Squared (R2): Percentage of the deviations from the mean that the model can explain\n",
    "- Mean Absolute Error (MAE): Average deviation of predictions from actual values (lenient with extreme deviations)\n",
    "- Mean Squared Error (MSE): Average squared deviation of predictions from actual values (unforgiving with extreme deviations)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
